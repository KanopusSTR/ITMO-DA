{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import youtokentome as yttm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:24:36.742042957Z",
     "start_time": "2024-02-09T10:24:36.699693425Z"
    }
   },
   "id": "36e05b1808195ed9",
   "execution_count": 390
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('train2.csv', 'r') as data_file:\n",
    "    with open('train.csv', 'a') as output_file:\n",
    "        for line in data_file:\n",
    "            output_file.write(\" \".join(line.split()).lower())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:24:39.457093011Z",
     "start_time": "2024-02-09T10:24:39.413050531Z"
    }
   },
   "id": "b26b589804cf2dcf",
   "execution_count": 391
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:24:42.278581250Z",
     "start_time": "2024-02-09T10:24:42.272400664Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training parameters\n",
      "  input: train.csv\n",
      "  model: example.model\n",
      "  vocab_size: 5000\n",
      "  n_threads: 8\n",
      "  character_coverage: 1\n",
      "  pad: 0\n",
      "  unk: 1\n",
      "  bos: 2\n",
      "  eos: 3\n",
      "\n",
      "reading file...\n",
      "learning bpe...\n",
      "number of unique characters in the training data: 61\n",
      "number of deleted characters: 0\n",
      "number of unique characters left: 61\n",
      "id: 1000=455+174              freq: 608         subword: ▁silent=▁sil+ent\n",
      "id: 2000=95+528               freq: 208         subword: asure=as+ure\n",
      "id: 3000=77+2363              freq: 112         subword: ▁funn=▁f+unn\n",
      "id: 4000=389+20               freq: 72          subword: ▁unm=▁un+m\n",
      "model saved to: example.model\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"train.csv\"\n",
    "model_path = \"example.model\"\n",
    "\n",
    "# Training model\n",
    "a = yttm.BPE.train(data=train_data_path, vocab_size=5000, model=model_path)\n",
    "\n",
    "# Loading model\n",
    "bpe = yttm.BPE(model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                 id                                       comment_text  toxic\n0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e617e2489abe9bca</td>\n      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9250cf637294e09d</td>\n      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ce1aa4592d5240ca</td>\n      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48105766ff7f075b</td>\n      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0543d4f82e5470b6</td>\n      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_toxicity.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:24:44.784687478Z",
     "start_time": "2024-02-09T10:24:44.703573004Z"
    }
   },
   "id": "a31d68613b626ed",
   "execution_count": 393
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size 5000 \n",
      "Toxic comments amount 437\n"
     ]
    }
   ],
   "source": [
    "toxic_count = 0\n",
    "for condition in df[\"toxic\"]:\n",
    "    toxic_count += condition\n",
    "print(\"Dataset size %.3d \\nToxic comments amount %.3d\" % (len(df), toxic_count))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:27:29.691854381Z",
     "start_time": "2024-02-09T10:27:29.617990269Z"
    }
   },
   "id": "9bd4aacf9fbe7fd3",
   "execution_count": 399
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.2)\n",
    "train, test = train_test_split(train, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T10:27:41.948087989Z",
     "start_time": "2024-02-09T10:27:41.926451069Z"
    }
   },
   "id": "da0531dd65b42838",
   "execution_count": 400
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "def encode(q):\n",
    "    text = bpe.encode(q, output_type=yttm.OutputType.ID)\n",
    "    \n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    l = min(N, len(text))\n",
    "    enc[N-l:] = text[:l]\n",
    "    text = enc[:]\n",
    "        \n",
    "    return np.array(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:53:11.625202154Z",
     "start_time": "2024-02-09T17:53:11.580878257Z"
    }
   },
   "id": "a319bc7dc5218126",
   "execution_count": 560
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.text = [encode(\" \".join(q.split()).lower()) for q in df[\"comment_text\"]]\n",
    "        self.y = list(df[\"toxic\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.text[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, np.array([y])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:53:12.291690769Z",
     "start_time": "2024-02-09T17:53:12.232623389Z"
    }
   },
   "id": "ae6a4960c2b04853",
   "execution_count": 561
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collate():\n",
    "    return torch.Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:53:12.694328433Z",
     "start_time": "2024-02-09T17:53:12.689466739Z"
    }
   },
   "id": "ad5173839655f887",
   "execution_count": 562
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_ds = QuoraDataset(train)\n",
    "valid_ds = QuoraDataset(valid)\n",
    "test_ds = QuoraDataset(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:53:13.255643639Z",
     "start_time": "2024-02-09T17:53:13.066860830Z"
    }
   },
   "id": "5c5391a4749af5f0",
   "execution_count": 563
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:53:13.955275111Z",
     "start_time": "2024-02-09T17:53:13.862345650Z"
    }
   },
   "id": "99a9e31c5dedbed4",
   "execution_count": 564
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=2)\n",
    "        self.linear = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_emb = self.embeddings(x)\n",
    "        x_drop = self.dropout(x_emb)\n",
    "        out_pack, (ht, ct) = self.lstm(x_drop)\n",
    "        ht = torch.cat((ht[-2, :, :], ht[-1, :, :]), dim=1)\n",
    "        out = self.linear(ht)\n",
    "        out = self.dropout(out)\n",
    "        return self.linear2(F.relu(out))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:32:30.220389737Z",
     "start_time": "2024-02-09T19:32:30.135084655Z"
    }
   },
   "id": "8e100120301b537e",
   "execution_count": 739
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def val_metrics(model, dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y in dl:\n",
    "        y = y.float()\n",
    "        y_model = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_model, y)\n",
    "        y_pred = y_model > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += batch_size\n",
    "        sum_loss += loss.item()\n",
    "    return sum_loss/total, correct/total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:32:30.600188692Z",
     "start_time": "2024-02-09T19:32:30.560618949Z"
    }
   },
   "id": "9c731ca1a91baf4d",
   "execution_count": 740
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            y = y.float()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            total += batch_size\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:32:30.964376496Z",
     "start_time": "2024-02-09T19:32:30.959612058Z"
    }
   },
   "id": "c2a8cec4d4ed1286",
   "execution_count": 741
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = TextClassificationModel(5000, 50, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:32:31.324586065Z",
     "start_time": "2024-02-09T19:32:31.316604454Z"
    }
   },
   "id": "8c7846d3e46da0b1",
   "execution_count": 742
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.004 val loss 0.004 and val accuracy 0.890\n",
      "train loss 0.002 val loss 0.005 and val accuracy 0.903\n",
      "train loss 0.001 val loss 0.009 and val accuracy 0.910\n",
      "train loss 0.001 val loss 0.006 and val accuracy 0.908\n",
      "train loss 0.001 val loss 0.008 and val accuracy 0.910\n",
      "train loss 0.000 val loss 0.010 and val accuracy 0.914\n",
      "train loss 0.000 val loss 0.010 and val accuracy 0.913\n",
      "train loss 0.000 val loss 0.007 and val accuracy 0.907\n",
      "train loss 0.000 val loss 0.009 and val accuracy 0.911\n",
      "train loss 0.000 val loss 0.010 and val accuracy 0.914\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=50, lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:34:15.724729441Z",
     "start_time": "2024-02-09T19:32:31.773821585Z"
    }
   },
   "id": "e2fae52e678466ea",
   "execution_count": 743
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.009 and test accuracy 0.922\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = val_metrics(model, test_dl)\n",
    "print(\"test loss %.3f and test accuracy %.3f\" % (test_loss, test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:34:16.044125836Z",
     "start_time": "2024-02-09T19:34:15.726961082Z"
    }
   },
   "id": "8e145e1627c0c591",
   "execution_count": 744
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f0fb173b7e0c89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
